# TrendCre- **ğŸ“ Comprehensive Logging**: Multi-level logging with file ro## ğŸ“ˆ Sample Output

```
## ï¿½ï¸ Development

```bash
# ## ğŸ“‹ Troubleshooting

**Slow Performance**: Check network connectivity, consider adding domains to blacklist
**Missing Content**: Verify URLs are accessible, check if domains are blacklisted
**Database Issues**: Ensure SQLite permissions and disk spacerements
Python 3.8+
Dependencies: requests, beautifulsoup4, sqlalchemy, tqdm

# Key Files
src/aggregation/        # Core module (see module README)
scripts/daily_aggregation.py  # Main execution script
requirements.txt        # All dependencies
```ent fetching enabled (with domain blacklisting for speed)
ğŸ” Step 1/5: Checking existing database content... âœ…
ğŸ“° Step 2/5: Scraping latest AI news... âœ… Found 8 articles
ğŸ“„ Step 3/5: Fetching full article content... âœ… 6/8 with content
ğŸ’¾ Step 4/5: Saving to database... âœ… Saved: 3, Duplicates: 5
ğŸ“ Step 5/5: Exporting to markdown... âœ… Exported to: exports/tldr_ai_news_2025-07-27.md
```

## ğŸ—„ï¸ Database & Exporterformance tracking
- **ğŸ’¾ Robust Storage**: SQLite database with comprehensive metadatae - TLDR AI News Aggregator

A high-performance news aggregation system that scrapes, processes, and stores AI-related articles from TLDR AI newsletter with intelligent content extraction and optimization features.

## ğŸš€ Key Features

- **ğŸ”„ Full Content Extraction**: Fetches complete article content from original sources
- **âš¡ Smart Performance**: Domain blacklisting prevents timeouts, 15-20s total runtime
- **ğŸ¯ Intelligent Deduplication**: Multiple strategies prevent duplicate content
- **ğŸ“Š Progress Visualization**: Real-time progress bars for all operations
- **ï¿½ Comprehensive Logging**: Multi-level logging with file rotation and performance tracking
- **ï¿½ğŸ’¾ Robust Storage**: SQLite database with comprehensive metadata
- **ğŸ“„ Markdown Export**: Professional formatted reports
- **ğŸ›¡ï¸ Error Resilience**: Graceful fallbacks and comprehensive error handling

## âš¡ Quick Start

```bash
# Clone and setup
git clone https://github.com/hsiaotingluv/TrendCreate.git
cd TrendCreate
pip install -r requirements.txt

# Run daily aggregation
python scripts/daily_aggregation.py
```

## ğŸ“Š Performance

- **â±ï¸ Total Runtime**: 15-20 seconds (optimized from 60+ seconds)
- **ğŸš€ Content Fetching**: ~5-10 seconds for 8 articles
- **ğŸ’¾ Database Operations**: <1 second
- **ğŸ“ˆ Success Rate**: High reliability with fallback strategies

## ğŸ“ Architecture

```
TrendCreate/
â”œâ”€â”€ src/aggregation/           # Core aggregation module
â”‚   â”œâ”€â”€ models.py             # Unified NewsItem SQLAlchemy model
â”‚   â”œâ”€â”€ tldr_scraper.py       # Main scraper orchestrator
â”‚   â”œâ”€â”€ content_fetcher.py    # Optimized content extraction
â”‚   â”œâ”€â”€ database.py           # Database operations
â”‚   â””â”€â”€ logging_config.py     # Comprehensive logging system
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ daily_aggregation.py  # Main execution script
â”œâ”€â”€ data/                     # SQLite database storage
â”œâ”€â”€ logs/                     # Generated log files
â”œâ”€â”€ exports/                  # Generated markdown reports
â””â”€â”€ requirements.txt          # Dependencies
```

## ğŸ”§ System Overview

**NewsItem Model** - Unified SQLAlchemy model with business logic and persistence
**Content Fetcher** - High-performance extraction with domain blacklisting
**TLDR Scraper** - Main orchestrator coordinating all operations
**Database Manager** - Robust SQLite operations with duplicate detection
**Logging System** - Multi-level logging with file rotation and performance metrics
**Daily Aggregation** - Main execution script with progress visualization

## âš™ï¸ Performance Optimizations

### Domain Blacklisting
```python
BLACKLISTED_DOMAINS = {'minihf.com'}  # Skip slow/problematic domains
```

### Timeout Management
- Connection timeout: 8 seconds
- Read timeout: 8 seconds  
- Retry attempts: 2
- Intelligent fallback to summaries

## ï¿½ Sample Output

```
ğŸ“„ Full content fetching enabled (with domain blacklisting for speed)
ğŸ” Step 1/5: Checking existing database content... âœ…
ğŸ“° Step 2/5: Scraping latest AI news... âœ… Found 8 articles
ğŸ“„ Step 3/5: Fetching full article content... âœ… 6/8 with content
ğŸ’¾ Step 4/5: Saving to database... âœ… Saved: 3, Duplicates: 5
ğŸ“ Step 5/5: Exporting to markdown... âœ… Exported to: exports/tldr_ai_news_2025-07-27.md
```

## ï¿½ï¸ Database & Export

**Database Schema**: SQLite with NewsItem model including content hashing for deduplication
**Export Format**: Professional markdown reports with statistics and categorized content
**Duplicate Detection**: URL matching, content hashing, and title similarity

## ï¿½ï¸ Development

```bash
# Requirements
Python 3.8+
Dependencies: requests, beautifulsoup4, sqlalchemy, tqdm

# Key Files
src/aggregation/        # Core module (see module README)
scripts/daily_aggregation.py  # Main CLI entry point
requirements.txt        # All dependencies
```

## ï¿½ Advanced Features

- **ğŸ”„ Intelligent Retry Logic**: 2-attempt retry with exponential backoff
- **ğŸ“Š Progress Tracking**: Real-time tqdm progress bars
- **ğŸ›¡ï¸ Error Resilience**: Graceful fallbacks to TLDR summaries
- **âš¡ Performance Monitoring**: Built-in timing and statistics
- **ğŸ” Debug Support**: Comprehensive logging and error reporting

## ï¿½ Troubleshooting

**Slow Performance**: Check network connectivity, consider adding domains to blacklist
**Missing Content**: Verify URLs are accessible, check if domains are blacklisted
**Database Issues**: Ensure SQLite permissions and disk space

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

1. Fork repository
2. Create feature branch  
3. Add tests if applicable
4. Submit pull request

For detailed technical documentation, see `src/aggregation/README.md`
